<!doctype html><html lang=zh-hans><!doctype html><html><head><title>多页批量规则数据抓取解决方案</title><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="A blog maintained by an interesting programmer."><meta name=keywords content="Technology,Code,Program,Linux,"><meta name=author content="Xuanwo"><meta property="og:title" content="多页批量规则数据抓取解决方案"><meta property="og:description" content="A blog maintained by an interesting programmer."><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="https://xuanwo.io/2015/09/24/multi-page-data-spider/"><link rel="shortcut icon" href=/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.2/themes/algolia-min.css integrity="sha256-HB49n/BZjuqiCtQQf49OdZn63XuKFaxcIHWf0HNKte8=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.86011fe2120272b15cfe4299381bebaf7719f960a0f6117c9397371547aaeb2a.css integrity="sha256-hgEf4hICcrFc/kKZOBvrr3cZ+WCg9hF8k5c3FUeq6yo="><script defer src=/javascript/fontawesome.min.a066b72a16bb5f37fe57ab06f6409b5bf30239d82ab5a71987e6abcac78bf2f0.js integrity=sha256-oGa3Kha7Xzf+V6sG9kCbW/MCOdgqtacZh+aryseL8vA=></script><link href=http://gmpg.org/xfn/11 rel=profile><meta name=generator content="Hugo 0.72.0"></head><body class="min-h-screen font-sans leading-normal"><header><nav class="container text-gray"><div class="py-2 flex flex-col lg:flex-row flex-wrap justify-between items-center"><a class="text-2xl text-gray-900 hover:no-underline flex-shrink-0 font-normal" href=/>漩涡的博客</a><div class="flex flex-col lg:flex-row items-center w-full lg:w-auto"><a class="header-link flex-shrink-0 hover:no-underline hover:text-grey-700 relative mr-0 lg:mr-8 my-2 lg:my-0 text-gray-500" href=/about/>关于我</a>
<a class="header-link flex-shrink-0 hover:no-underline hover:text-grey-700 relative mr-0 lg:mr-8 my-2 lg:my-0 text-gray-500" href=/en-us/>English Version</a><div class=relative><span class=algolia-autocomplete style=position:relative;display:inline-block;direction:ltr><input id=search-box class="transition-colors duration-100 ease-in-out focus:outline-0 border border-transparent focus:bg-white focus:border-gray-300 placeholder-gray-500 rounded-lg bg-gray-200 py-2 pr-4 pl-10 block w-full appearance-none leading-normal ds-input" type=text autocomplete=off spellcheck=false role=combobox dir=auto style=position:relative;vertical-align:top></span><div class="pointer-events-none absolute inset-y-0 left-0 pl-4 flex items-center"><svg class="fill-current pointer-events-none text-gray-600 w-4 h-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20"><path d="M12.9 14.32a8 8 0 111.41-1.41l5.35 5.33-1.42 1.42-5.33-5.34zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg></div></div></div></div></nav></header><main class=flex-1><article class="container pt-16"><header class="pb-4 mb-8 border-b"><h1 class="my-2 text-black leading-tight">多页批量规则数据抓取解决方案</h1><ul class="mb-0 pb-0 text-sm text-grey-500"><li class="block sm:inline-block mr-3"><time class="text-lg font-light" datetime=2015-09-24T08:04:13.000+00:00 itemprop=datePublished>2015-09-24</time></li><li class="block sm:inline-block mr-3"><a class="text-lg font-light" href=https://xuanwo.io/tags/qingcloud><span>#QingCloud</span></a>
<a class="text-lg font-light" href=https://xuanwo.io/tags/work><span>#Work</span></a></li></ul></header><div class=post-content><p>最近完成的一个工作是要抓取某公司的合作伙伴信息，跟上一次的区别在于，这个公司调用了Salesforce之类的第三方CRM服务。合作伙伴的详细信息是需要点开对应的连接之后才可以获得。</p><h1 id=分析>分析</h1><p>毫无疑问，这次的工作难度高了很多。不过还是遵循一样的思路——获取，整理，导入。</p><h2 id=获取>获取</h2><p>首先解决获取问题，不难发现每一个合作伙伴的对应详细信息网址都是有规律的，通过传入一个类似于id的参数来获得，也就是说问题转换成如何获取所有合作伙伴的id。通过分析HTML代码可以发现（在F12中查看，而不是直接查看源代码），id出现的位置都有着相当的特征，通过正则即可提取。
得到id之后，就可以模仿着构造出对应的请求链接。得到请求链接之后，就可以用各种网络库来下载相关网页了。这一次，我使用了简单粗暴的curl。</p><h2 id=整理>整理</h2><p>得到了包含联系方式的文件，我需要从中提取出我需要的信息，自然想到了正则。但是经过多次试错之后发现，正则并不能完美实现我的需求，总是存在部分疏漏。有数据量较大，冗余文本过多，我无法一一排查正则表达式何处出错，故不得不放弃了这一方案。最后实现的思路是通过C++编写相关代码，搜索联系方式前后出现的特征串（比如<code>电话</code>或<code>Phone</code>之类）。</p><h2 id=导入>导入</h2><p>数据的导入仍然是通过Excel打开文本的形式导入，不过要处理好号码粘连在一起的部分条目。比如说：开头数字相近的长度为在7到8之间的串，以及一个1开头的长度为11的串。这些处理完毕之后，记得统一一下字体及字号，照顾一下阅读这些数据的人的感受~</p><h1 id=方案>方案</h1><h2 id=适用范围>适用范围</h2><ul><li>多页（链接有规律）</li><li>批量</li><li>规则数据</li></ul><h2 id=工具>工具</h2><ul><li>Chrome</li><li>curl</li><li>Sublime Text 3（支持正则表达式）</li><li>Clion</li><li>Excel 2016</li></ul><h2 id=流程>流程</h2><ul><li>使用Chrome获得包含合作伙伴id的HTML代码</li><li>使用正则获取对应id并构造请求链接</li><li>使用curl下载对应的HTML</li><li>使用正则提取合作伙伴的联系方式</li><li>整理之后导入Excel</li></ul><h1 id=坑点>坑点</h1><h2 id=想当然的使用正则>想当然的使用正则</h2><p>正则强大是强大，但是如果自己在不了解具体的数据构成方式的时候，错误的随意的使用正则，往往只能得到错误的结果。为了这个坑，我调试了大概有两个小时，铭记在心。</p><h1 id=总结>总结</h1><p>这次工作娴熟了很多，对这一类问题已经有了比较系统的思路，区别仅仅是在于如何针对特定的规则改变自己使用工具的方式而已。</p><h1 id=更新日志>更新日志</h1><ul><li>2015年09月24日 完成初稿</li></ul></div></article></main><footer><div class=container><div class="flex flex-col md:flex-row justify-between py-4"><div class="flex-shrink-0 flex flex-wrap md:w-1/3 mt-4 md:mt-0"><span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/archives/>归档</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/categories/>分类</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/tags/>标签</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/series/>系列</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/blogroll/>友链</a></span></div><ul class="flex sm:w-1/2 md:w-1/3 text-center lg:text-right"><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=/index.xml><i class="fas fa-rss"></i></a></li><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=https://github.com/Xuanwo><i class="fas fa-github"></i></a></li><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=https://t.me/xuanwo_read_later><i class="fas fa-telegram-plane"></i></a></li><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=https://twitter.com/OnlyXuanwo><i class="fas fa-twitter"></i></a></li></ul></div></div><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.js integrity="sha256-KiHRWUnyloQ6hvdcRAfi7hwExmviOdyWTRFBLmDNhHc=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js integrity="sha256-YVWQosorZnr6fALvOW9VALYuInld27RkSPkElGBdCaU=" crossorigin=anonymous></script><script defer src=/javascript/algolia_search.min.78d1e38d6ad73f7bc248762cbf4f70b246476baa3288e2a780ec7ac11f0e669d.js integrity=sha256-eNHjjWrXP3vCSHYsv09wskZHa6oyiOKngOx6wR8OZp0=></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-51515330-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></footer></body></html>