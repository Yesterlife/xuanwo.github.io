<!doctype html><html lang=zh-hans><!doctype html><html><head><title>动态网页数据抓取踩坑分享</title><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="A blog maintained by an interesting programmer."><meta name=keywords content="Technology,Code,Program,Linux,"><meta name=author content="Xuanwo"><meta property="og:title" content="动态网页数据抓取踩坑分享"><meta property="og:description" content="A blog maintained by an interesting programmer."><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="https://xuanwo.io/2016/09/13/dynamic-page-data-spider/"><link rel="shortcut icon" href=/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/instantsearch.css@7.4.2/themes/algolia-min.css integrity="sha256-HB49n/BZjuqiCtQQf49OdZn63XuKFaxcIHWf0HNKte8=" crossorigin=anonymous><link rel=stylesheet href=/css/main.min.07c86322f1d5e9d3b42182e40c818cc8042d461f64661e263ffaad968d672df1.css integrity="sha256-B8hjIvHV6dO0IYLkDIGMyAQtRh9kZh4mP/qtlo1nLfE="><script defer src=/javascript/fontawesome.min.a066b72a16bb5f37fe57ab06f6409b5bf30239d82ab5a71987e6abcac78bf2f0.js integrity=sha256-oGa3Kha7Xzf+V6sG9kCbW/MCOdgqtacZh+aryseL8vA=></script><link href=http://gmpg.org/xfn/11 rel=profile><meta name=generator content="Hugo 0.72.0"></head><body class="min-h-full font-sans leading-normal"><header><nav class="container text-gray px-4"><div class="py-2 flex flex-col lg:flex-row flex-wrap justify-between items-center"><a class="text-2xl text-gray-900 hover:no-underline flex-shrink-0 font-normal" href=/>漩涡的博客</a><div class="flex flex-col lg:flex-row items-center w-full lg:w-auto"><a class="header-link flex-shrink-0 hover:no-underline hover:text-grey-700 relative mr-0 lg:mr-8 my-2 lg:my-0 text-gray-500" href=/about/>关于我</a>
<a class="header-link flex-shrink-0 hover:no-underline hover:text-grey-700 relative mr-0 lg:mr-8 my-2 lg:my-0 text-gray-500" href=/en-us/>English Version</a><div class=relative><span class=algolia-autocomplete style=position:relative;display:inline-block;direction:ltr><input id=search-box class="transition-colors duration-100 ease-in-out focus:outline-0 border border-transparent focus:bg-white focus:border-gray-300 placeholder-gray-500 rounded-lg bg-gray-200 py-2 pr-4 pl-10 block w-full appearance-none leading-normal ds-input" type=text autocomplete=off spellcheck=false role=combobox dir=auto style=position:relative;vertical-align:top></span><div class="pointer-events-none absolute inset-y-0 left-0 pl-4 flex items-center"><svg class="fill-current pointer-events-none text-gray-600 w-4 h-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20"><path d="M12.9 14.32a8 8 0 111.41-1.41l5.35 5.33-1.42 1.42-5.33-5.34zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg></div></div></div></div></nav></header><main class="flex-1 px-4"><article class="container pt-16"><header class="pb-4 mb-8 border-b"><h1 class="my-2 text-black leading-tight">动态网页数据抓取踩坑分享</h1><ul class="mb-0 pb-0 text-sm text-grey-500"><li class="block sm:inline-block mr-3"><time class="text-lg font-light" datetime=2016-09-13T01:58:33.000+00:00 itemprop=datePublished>2016-09-13</time></li><li class="block sm:inline-block mr-3"><a class="text-lg font-light" href=https://xuanwo.io/tags/qingcloud><span>#QingCloud</span></a>
<a class="text-lg font-light" href=https://xuanwo.io/tags/work><span>#Work</span></a></li></ul></header><div class=post-content><p>之前做了一些数据抓取的工作，期间也踩了一些坑，所以有了这篇文章。</p><h2 id=动态网页数据源获取>动态网页数据源获取</h2><p>需要抓取的页面是使用<a href=https://facebook.github.io/react/>React</a> JavaScript 框架开发的，所有的页面都是客户端渲染而成，这也就导致我只能看到一个个的 data-id ，没有办法直接获取数据。这就涉及到一个我之前没有接触过的领域——动态网页爬虫。
一番 Google 之后，我了解到动态网页爬虫大致上可以通过以下两种方法实现：</p><ul><li>分析网页代码结构和请求，找到数据源的请求链接</li><li>调用Webkit渲染之后再进行抓取</li></ul><p>第二种方法相当于在命令行中跑一个浏览器，一个页面一个页面的打开，效率可想而知。再加上待抓取页面的 DOM 结构本来就比较复杂，没有添加相应的 class 和 id，导致即使渲染出来了想要抓到自己需要的数据也非常费劲。
于是只能采用第一种方案：分析了一下网页的代码之后发现所有的数据都是通过一个接口返回的。使用 Chrome 审查工具中的 <code>Network</code> 工具可以获取到所有的网络请求，在里面搜索 <code>JSON</code> ，找到了一个 JSON 的请求。点开一看正是我们需要的数据，解决了动态网页数据源的问题。</p><h2 id=分类不统一>分类不统一</h2><p>这个坑主要出在自己对目标网页的数据特性挖掘的不够。一开始以为目标网页是按照一个特定的分类来区分的，但是后来发现这个标准并不统一，最后抓取到的数据不在一个维度上。正当自己准备开工写很多特判的时候发现，如果从另外一个维度来索取数据的话，所有的数据都是统一的。
在这个案例中，就是将人为的分类切换成通过价格来获取数据，通过选择所有价格，就能获取到所有的数据，不需要再对不同维度的分类进行特判。
这个与其说是技术问题，更多的是一个经验的问题。</p><h2 id=页面内部js执行>页面内部JS执行</h2><p>这个坑就比较有趣了。
目标网页除了通过一个特定的接口获取数据之外，还会在页面内部通过 JavaScript 来直接传递数据。背后的技术考量不得而知，但是摆在我面前的问题就是我要如何获取这些 JavaScript 代码中的数据。
思考了一下之后想到了两种方案：</p><ul><li>自行匹配需要的字符串</li><li>通过 phatomjs 等工具执行页面内部的 js 代码，并输出需要的数据变量</li></ul><p>自行匹配的问题在于，我需要匹配的字符串的格式不一，很难直接匹配出我需要的数据。而通过 phatomjs 执行，就能比较好的解决这个问题。</p><p>一个比较脏的解决方案是这样的：</p><ol><li>下载整个HTML页面到 <code>test.html</code></li><li>通过 bs4 获取到所有的 <code>&lt;script></code> 标签内部的内容</li><li>将我们需要的那个标签输出到一个 <code>data.js</code> 文件中</li><li>之后把将数据构造成 json 的 js 代码写入 <code>data.js</code> 文件</li><li>通过 phatomjs 来执行代码</li><li>将输出通过 <code>json.loads</code> 载入并 append 到我们的数据数组中</li></ol><p>这样，我们就获得了页面内部js代码中数据的json形式。</p><blockquote><p>phatomjs 中执行的代码最后，千万要记得加上 <code>phatom.exit()</code>，否则不会自行退出。</p></blockquote><h2 id=phatomjs报错>phatomjs报错</h2><p><a href=https://cli.xuanwo.io/Tools/phatomjs.html#qxcbconnection-could-not-connect-to-display>https://cli.xuanwo.io/Tools/phatomjs.html#qxcbconnection-could-not-connect-to-display</a></p><p>当代码放到服务器上运行时候，出现了这样的报错：</p><pre><code>QXcbConnection: Could not connect to display
</code></pre><p>这是因为源中的phatomjs默认运行在图形界面下，只需要在运行前执行：</p><pre><code>export QT_QPA_PLATFORM=offscreen
</code></pre><p>即可。</p><h2 id=线程调度>线程调度</h2><p>这个坑就比较隐蔽了，重复调试了很久。
在前面的流程中，我们有一个下载HTML页面并使用bs4解析的步骤。我之前的实现是通过<code>subprocess.Popen()</code>直接调用 <code>curl</code> 之后，就打开<code>test.html</code>。这样的实现导致了这样的一个问题：有可能网页还没有下载完，我就开始进行解析了，这样就会导致我的解析内容跟本就不正确。也就是说，<code>subprocess.Popen()</code> 不是一个阻塞的过程，它在调用完 <code>curl</code> 之后不会等到 <code>curl</code> 返回再结束。
定位到问题的话，解决起来就很容易了。通过查阅文档，我知道了可以通过这种方法来保证命令执行完毕再执行下一行代码：</p><pre><code>child = subprocess.Popon(&quot;curl xxxx.com &gt; test.html&quot;, shell=True)
child.wait()
</code></pre><h2 id=回顾--总结>回顾 & 总结</h2><p>这个小小的玩意儿开发没花多久，但是学到了很多东西。从之前自己一直以为很难不敢尝试的动态网页抓取到 Python subprocess 线程调度，果然不踩坑就不会有新的收获。
这次开发的东西比较敏感，涉及到公司内部的一些事务，所以代码就不开源出来了。有什么想法或者问题可以直接在评论区里提出来，我会尽量回复的。因为是一个一次性的小套件，所以没有怎么考虑优化上的事情，如果有更好的解决方案，也欢迎大家一起探讨，说不定下次就用上了呢~</p></div></article></main><footer><div class="container px-4"><div class="flex flex-col md:flex-row justify-between py-4"><div class="flex-shrink-0 flex flex-wrap md:w-1/3 mt-4 md:mt-0"><span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/archives/>归档</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/categories/>分类</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/tags/>标签</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/series/>系列</a></span>
<span class="flex-shrink-0 w-1/5 mb-2 text-center lg:text-left"><a class="footer-link relative text-gray-500 hover:text-gray-100 hover:no-underline" href=/blogroll/>友链</a></span></div><ul class="flex sm:w-1/2 md:w-1/3 text-center lg:text-right"><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=/index.xml><i class="fas fa-rss"></i></a></li><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=https://github.com/Xuanwo><i class="fas fa-github"></i></a></li><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=https://t.me/xuanwo_read_later><i class="fas fa-telegram-plane"></i></a></li><li class=w-1/4><a class="text-gray-500 hover:text-gray-800" href=https://twitter.com/OnlyXuanwo><i class="fas fa-twitter"></i></a></li></ul></div></div><script src=https://cdn.jsdelivr.net/npm/algoliasearch@4.2.0/dist/algoliasearch-lite.umd.js integrity="sha256-KiHRWUnyloQ6hvdcRAfi7hwExmviOdyWTRFBLmDNhHc=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js integrity="sha256-YVWQosorZnr6fALvOW9VALYuInld27RkSPkElGBdCaU=" crossorigin=anonymous></script><script defer src=/javascript/algolia_search.min.78d1e38d6ad73f7bc248762cbf4f70b246476baa3288e2a780ec7ac11f0e669d.js integrity=sha256-eNHjjWrXP3vCSHYsv09wskZHa6oyiOKngOx6wR8OZp0=></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-51515330-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></footer></body></html>